# -*- coding: utf-8 -*-
"""Copy of Combined Model with Adam.ipynb

Automatically generated by Colaboratory.
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip /content/drive/MyDrive/Thesis/Dataset/Normal

!nvidia-smi -L

import os
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras import layers
from tensorflow.keras import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score, classification_report
from tensorflow.keras.utils import plot_model

"""##Data Generators
#### Data Augmentaion
Preparing Data for model training
"""

# TRAINING_DIR = '/content/drive/MyDrive/Thesis/Dataset/ResizedImages/TRAINITNG'
# VALIDATION_DIR = '/content/drive/MyDrive/Thesis/Dataset/ResizedImages/VALIDATION'
# TESTING_DIR = '/content/drive/MyDrive/Thesis/Dataset/ResizedImages/TESTING'

TRAINING_DIR = '/content/Training'
VALIDATION_DIR = '/content/Validation'
TESTING_DIR = '/content/Testing'

train_datagen = ImageDataGenerator(
      rescale=1./255,
      width_shift_range=0.15,
      height_shift_range=0.15,
      zoom_range=0.15,
      shear_range=10.0,
      horizontal_flip=True,
      brightness_range=(1.4,1.4),
      fill_mode='nearest'
    )

train_generator = train_datagen.flow_from_directory(
    TRAINING_DIR,
    target_size=(500, 400),
    batch_size=24,
    shuffle=True,
    # color_mode="grayscale",
    class_mode='binary')


validation_datagen = ImageDataGenerator(
    rescale=1./255
    )
validation_generator = validation_datagen.flow_from_directory(
        VALIDATION_DIR,
        target_size=(500, 400),
        batch_size=8,
        # color_mode="grayscale",
        class_mode='binary')

testing_datagen = ImageDataGenerator(
    rescale=1./255
    )
testing_generator = testing_datagen.flow_from_directory(
        TESTING_DIR,
        shuffle=False,
        target_size=(500, 400),
        # color_mode="grayscale",
        class_mode='binary')

"""##Callbacks"""

def customCallbacks(checkpoint_filepath):
  class CustomCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
      if(logs.get('val_accuracy')>=0.90):
        print("\nReached 90.0% accuracy so cancelling training!")
        self.model.stop_training = True

  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
      filepath=checkpoint_filepath,
      save_weights_only=True,
      monitor='val_accuracy',
      mode='max',
      save_best_only=True)

  earlyStoppingCallback = tf.keras.callbacks.EarlyStopping(
      monitor='loss', 
      patience=4, 
      mode='auto', 
      baseline=None, 
      restore_best_weights=True)
  
  ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau(
      monitor='val_loss', 
      factor=0.1, 
      patience=5, 
      mode='auto')
  
  return { '90stop' : CustomCallback,
          'checkpoint' : model_checkpoint_callback,
          'earlyStopping': earlyStoppingCallback,
          'reduce': ReduceLROnPlateau}

"""##Helper Functions"""

# Load and freeze a model
def makeModel(modelfunction):
  pre_trained_model = modelfunction(input_shape = (500, 400, 3), 
                                include_top = False, 
                                weights = 'imagenet')
  for layer in pre_trained_model.layers:
    layer.trainable = False

  return pre_trained_model

# Add top layers to pre_trained_model
def addTopLayers(pre_trained_model):
  x = layers.GlobalAveragePooling2D()(pre_trained_model.output)
  # x = layers.Flatten()()
  x = layers.Dense(512, activation= tf.nn.relu,  kernel_regularizer= 'l2')(x)
  x = layers.Dense(512, activation= tf.nn.relu,  kernel_regularizer= 'l2')(x)
  # x = layers.Dropout(0.2)(x)
  x = layers.Dense(1, activation='sigmoid')(x)           
  model = Model( pre_trained_model.input, x)
  return model


def trainModel(model, callbacks):
  model.compile(
      optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001),
      loss = 'binary_crossentropy', 
      metrics = ['accuracy']
      )
  
  history = model.fit(
      train_generator,
      epochs=30,
      validation_data=validation_generator,
      # validation_steps=4,
      verbose = 1,
      callbacks = callbacks
      )
  
  return model, history

def showStatistics(history):
  acc = history.history['accuracy']
  val_acc = history.history['val_accuracy']
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  epochs = range(len(acc))

  plt.plot(epochs, acc, 'r', label='Training accuracy')
  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
  plt.title('Training and validation accuracy')
  plt.legend(loc=0)
  plt.ylim(ymin=0)
  plt.figure()
  plt.show()

  plt.plot(epochs, loss, 'r', label='Training loss')
  plt.plot(epochs, val_loss, 'b', label='Validation loss')
  plt.title('Training and validation loss')
  plt.legend(loc=0)
  plt.ylim(ymin=0)
  plt.figure()
  plt.show()

def testModel(model):
  y_pred = model.predict(testing_generator).round().astype(int)[:,0]
  print('Validation Accuracy:')
  print(accuracy_score(testing_generator.classes, y_pred))

  print('\nConfusion Metrix')
  print(confusion_matrix(testing_generator.classes, y_pred))

  print('\nF1 Score:')
  print(f1_score(testing_generator.classes, y_pred))

  print('\nPrecision Score:')
  print(precision_score(testing_generator.classes, y_pred))

  print('\nRecall Score:')
  print(recall_score(testing_generator.classes, y_pred))

  print('\nClassification Report:')
  print(classification_report(testing_generator.classes, y_pred))

def saveHistoryFile(history, path):

  # convert the history.history dict to a pandas DataFrame:     
  hist_df = pd.DataFrame(history.history) 

  # save to csv: 
  with open(path, mode='w') as f:
      hist_df.to_csv(f)

"""#ResNet50v2 Model"""

from tensorflow.keras.applications import ResNet50V2
pre_trained_model = makeModel(ResNet50V2)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/ResNet50V2/"
modelPath = "/content/drive/MyDrive/Thesis/ResNet50V2/ResNet50V2-with-Adam.h5"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)





"""#ResNet152V2 Model"""

from tensorflow.keras.applications.resnet_v2 import ResNet152V2
pre_trained_model = makeModel(ResNet152V2)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/ResNet152V2/"
modelPath = checkpoint_filepath + "ResNet152V2-with-Adam.h5"
HistoryFilePath = checkpoint_filepath + "ResNet152V2-with-Adam.csv"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.layers

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

plot_model(model)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)

saveHistoryFile(history, HistoryFilePath)





"""#VGG16 Model"""

from tensorflow.keras.applications.vgg16 import VGG16
pre_trained_model = makeModel(VGG16)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/VGG16/"
modelPath = checkpoint_filepath + "VGG16-with-Adam.h5"
HistoryFilePath = checkpoint_filepath + "VGG16-with-Adam.csv"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)

saveHistoryFile(history, HistoryFilePath)



"""#VGG19 Model"""

from tensorflow.keras.applications.vgg19 import VGG19
pre_trained_model = makeModel(VGG19)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/VGG19/"
modelPath = checkpoint_filepath + "VGG19-with-Adam.h5"
HistoryFilePath = checkpoint_filepath + "VGG19-with-Adam.csv"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)

saveHistoryFile(history, HistoryFilePath)



"""#InceptionV3 Model"""

from tensorflow.keras.applications.inception_v3 import InceptionV3
pre_trained_model = makeModel(InceptionV3)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/InceptionV3/"
modelPath = "/content/drive/MyDrive/Thesis/InceptionV3/InceptionV3-with-Adam.h5"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)





"""#DenseNet121 Model"""

from tensorflow.keras.applications.densenet import DenseNet121
pre_trained_model = makeModel(DenseNet121)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/DenseNet121/"
modelPath = "/content/drive/MyDrive/Thesis/DenseNet121/DenseNet121-with-Adam.h5"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

# model = tf.keras.models.load_model("/content/drive/MyDrive/Thesis/DenseNet121/DenseNet121-with-Adam.h5")

testModel(model)

model.save(modelPath)





"""#DenseNet169 Model"""

from tensorflow.keras.applications.densenet import DenseNet169
pre_trained_model = makeModel(DenseNet169)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/DenseNet169/"
modelPath = "/content/drive/MyDrive/Thesis/DenseNet169/DenseNet169-with-Adam.h5"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)





"""#DenseNet201 Model"""

from tensorflow.keras.applications.densenet import DenseNet201
pre_trained_model = makeModel(DenseNet201)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/DenseNet201/"
modelPath = "/content/drive/MyDrive/Thesis/DenseNet201/DenseNet201-with-Adam.h5"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

model =  tf.keras.models.load_model("/content/drive/MyDrive/Thesis/DenseNet201/DenseNet201-with-Adam.h5")

testModel(model)

model.save(modelPath)





"""#EfficientNetB0 Model"""

from tensorflow.keras.applications.efficientnet import EfficientNetB0
pre_trained_model = makeModel(EfficientNetB0)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/EfficientNetB0/"
modelPath = "/content/drive/MyDrive/Thesis/EfficientNetB0/EfficientNetB0-with-Adam.h5"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)





"""#EfficientNetB1 Model"""

from tensorflow.keras.applications.efficientnet import EfficientNetB1
pre_trained_model = makeModel(EfficientNetB1)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/EfficientNetB1/"
modelPath = "/content/drive/MyDrive/Thesis/EfficientNetB1/EfficientNetB1-with-Adam.h5"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

inbmodel, history = trainModBB el(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)





"""#EfficientNetB2 Model"""

from tensorflow.keras.applications.efficientnet import EfficientNetB2
pre_trained_model = makeModel(EfficientNetB2)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/EfficientNetB2/"
modelPath = checkpoint_filepath + "EfficientNetB2-with-Adam.h5"
HistoryFilePath = checkpoint_filepath + "EfficientNetB2-with-Adam.csv"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)

saveHistoryFile(history, HistoryFilePath)



"""#EfficientNetB3 Model"""

from tensorflow.keras.applications.efficientnet import EfficientNetB3
pre_trained_model = makeModel(EfficientNetB3)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/EfficientNetB3/"
modelPath = "/content/drive/MyDrive/Thesis/EfficientNetB3/EfficientNetB3-with-Adam.h5"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)





"""#EfficientNetB4 Model"""

from tensorflow.keras.applications.efficientnet import EfficientNetB4
pre_trained_model = makeModel(EfficientNetB4)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/EfficientNetB4/"
modelPath = "/content/drive/MyDrive/Thesis/EfficientNetB4/Denoised+CLAHE-EfficientNetB4-with-Adam.h5"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)





"""#EfficientNetB5 Model"""

from tensorflow.keras.applications.efficientnet import EfficientNetB5
pre_trained_model = makeModel(EfficientNetB5)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/EfficientNetB5/"
modelPath = checkpoint_filepath + "EfficientNetB5-with-Adam.h5"
HistoryFilePath = checkpoint_filepath + "EfficientNetB5-with-Adam.csv"

HistoryFilePath

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)

saveHistoryFile(history, HistoryFilePath)



"""#EfficientNetB6 Model"""

from tensorflow.keras.applications.efficientnet import EfficientNetB6
pre_trained_model = makeModel(EfficientNetB6)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/EfficientNetB6/"
modelPath = "/content/drive/MyDrive/Thesis/EfficientNetB6/EfficientNetB6-with-Adam.h5"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)





"""#EfficientNetB7 Model"""

from tensorflow.keras.applications.efficientnet import EfficientNetB7
pre_trained_model = makeModel(EfficientNetB7)

checkpoint_filepath = "/content/drive/MyDrive/Thesis/EfficientNetB7/"
modelPath = "/content/drive/MyDrive/Thesis/EfficientNetB7/EfficientNetB7-with-Adam.h5"

pre_trained_model.summary()

model = addTopLayers(pre_trained_model)

model.summary()

callbacks = customCallbacks(checkpoint_filepath)

model, history = trainModel(model, [callbacks['earlyStopping'], callbacks['checkpoint']])

showStatistics(history)

model.load_weights(checkpoint_filepath)

testModel(model)

model.save(modelPath)



